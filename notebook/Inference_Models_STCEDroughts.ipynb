{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Noisy Labels for Spatio-Temporal Drought Detection\n",
    "\n",
    "This notebook aims to provide users with the Spatio-Temporal Convolutional Encoder-Decoder (ST-CED) model trained with no label correction and with the SuperPixel-based Label Self-Correction (SPLSC) method. Users have the option to select from the different data splits and obtain the corresponding predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jordi/Documents/erc/home/jorcora/STCEDroughts\n",
      "\u001b[0m\u001b[01;34mcode\u001b[0m/  \u001b[01;34mconfigs\u001b[0m/  \u001b[01;34mdatabases\u001b[0m/  \u001b[01;34mjobs\u001b[0m/  \u001b[01;34mnotebook\u001b[0m/  \u001b[01;34mouts\u001b[0m/  STCEDroughts_2024.yml\n",
      "/home/jordi/Documents/erc/home/jorcora/STCEDroughts/code\n",
      "Compare.py  Evaluate_context.py  \u001b[0m\u001b[01;34mexperiments\u001b[0m/           _MAIN_.py  \u001b[01;34mutils\u001b[0m/\n",
      "\u001b[01;34mdataset\u001b[0m/    Evaluate.py          \u001b[01;34mexperiments_evaluate\u001b[0m/  \u001b[01;34mmodel\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jordi/Documents/erc/home/jorcora/STCEDroughts/\n",
    "%ls \n",
    "#%conda create -n my_new_env -f STCEDroughts_2024.yml\n",
    "\n",
    "%cd code\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse, yaml\n",
    "import torch\n",
    "import pickle\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# MODEL\n",
    "from model.GDIS_model_indices import MY_MODEL\n",
    "from model.arch import *\n",
    "\n",
    "# UTILS\n",
    "from utils.patch_map import M2P_P2M\n",
    "from utils.loss import compute_loss\n",
    "from utils.slice import crop_variable\n",
    "from utils.spx import SPXsLABEL\n",
    "from utils.GDIS_map import geoplot2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': {'name': 'SHIFT4L', 'model_init_file': '3Ds0', 'num_classes': 1, 'in_channels_climate': 5, 'encoder_1': 16, 'encoder_2': 32, 'encoder_3': 64, 'encoder_4': 128, 'decoder_4': 128, 'decoder_3': 64, 'decoder_2': 32, 'decoder_1': 16, 'slope': 0.1, 'dropout': 0.1, 'momentum': 0.1, 'PI': 0.01, 'conv_kernel_size': '(2,3,3)', 'last_conv_kernel_size': '(1,3,3)', 'pool_kernel_size': '(1,2,2)'}, 'SPX': {'SPX': 0, 'split_method': 'slic', 'npixels': 25, 'metric': 'mean', 'metric_eps_score': 'conf_score_entr', 'time_weight': True, 'softLabels': True, 'combined_labels': True, 'combined_losses': False, 'eps': 0.05, 'robustness': {'noise_level': 0.0, 'id_process': 0, 'n_process': 10, 'gen_id': 0}}, 'optimizer': {'lr': 0.001, 'wd': 0.0, 'loss': {'type': 'FL', 'gamma': 1}}, 'trainer': {'epochs': 10, 'monitor': 'auroc', 'mselection': 'mselection', 'early_stop': 500}}\n",
      "{'GDIS': {'root': '/home/jorcora/Location_Aware_AM/databases/GDIS', 'data_file': 'esdc-8d-0.083deg-1x2160x4320-2.1.1', 'labels_file': 'GDIS_EMDAT_droughts_masks.zarr', 'climatology_mean_file': 'climatology_mean', 'climatology_std_file': 'climatology_std', 'samples_info_file': 'SHIFT1500_2out07_pdroughtIn_4L', 'features': ['surface_moisture', 'root_moisture', 'gross_primary_productivity', 'transpiration', 'air_temperature_2m', 'evaporation', 'fapar_tip', 'leaf_area_index'], 'features_selected': [0, 1, 3, 4, 5], 'lat_slice': '73.5, 28.5', 'lon_slice': '-20.0, 68.0', 'time_slice': \"'January-2003','December-2015'\", 'resolution': 0.0833, 'input_size': '(126,126,10)', 'output_size': '(64,64,2)', 'unfold_train': False, 'unfold_val': False, 'unfold_test': True, 'load_past': True, 'n_samples': 1500, 'overlap': 0.75, 'min_p_drought': 0.1, 'min_non_nan_content': 0.0, 'distr_mode': 'independent', 'alpha': 0.05, 'mf_sampler_train': 1, 'mf_sampler_val': 1, 'fixed_samples_train': False, 'fixed_samples_val': True, 'remove_very_small': True, 'min_pixels': 0, 'connect_small_objects': True, 'min_dist': 115, 'same_for_all_times': True, 'plot_events': True, 'border3Dforms': '(5,90,90)', 'plot_3Dforms': True, 'margins3Dforms': 5, 'vismargin': 4, 'batch_size': 1, 'num_workers': 16, 'augment': False, 'augment_prob': 0.0, 'idt_ref_in': [6, 7], 'idt': -1, 'fdata': 'data_py1', 'train_slice': [\"'January-2003','December-2008'\"], 'val_slice': [\"'January-2009','December-2010'\"], 'test_slice': [\"'January-2011','December-2015'\"]}, 'HWSD': {'root': '/home/jorcora/Location_Aware_AM/databases/HWSD', 'context_file': 'HWSD.zarr', 'map_dominant_context_file': 'map_dominant_context.pt', 'features': ['CULTRF_2000', 'CULTIR_2000', 'CULT_2000', 'FOR_2000', 'GRS_2000', 'URB_2000', 'NVG_2000', 'WAT_2000'], 'features_selected': [0, 1, 2, 3, 4, 5, 6]}, 'DInd': {'root': '/home/jorcora/Location_Aware_AM/databases/DInd', 'indices_file': 'indices.zarr', 'features': ['SPEI1', 'SPEI12', 'CDI', 'EnsembleSMA', 'SMA'], 'features_selected': [0, 1, 2, 3], 'ref_timescale': 'model', 'commonMask': False}}\n"
     ]
    }
   ],
   "source": [
    "def setup(filename):\n",
    "    \"\"\"Loads configuration yaml file as a dictionary\n",
    "\n",
    "    :param filename: configuration file\n",
    "    :type filename: yaml\n",
    "    :return: configuration file\n",
    "    :rtype: dict\n",
    "    \"\"\"    \n",
    "    # Load YAML config file into a dict variable\n",
    "    with open(filename) as file:\n",
    "        # The FullLoader parameter handles the conversion from YAML\n",
    "        # scalar values to Python dictionary format\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    return config\n",
    "\n",
    "# Model and dataset configuration files\n",
    "parent_path = os.path.dirname(os.getcwd())\n",
    "dataset_config = setup(parent_path + '/configs/config_dataset.yaml')\n",
    "model_config = setup(parent_path + '/configs/config_model.yaml')\n",
    "\n",
    "# Select config files specific to model and fold\n",
    "arch_name = '3D'\n",
    "model_config['arch'].update(model_config['arch']['archs'][arch_name])\n",
    "del model_config['arch']['archs']\n",
    "print(model_config)\n",
    "\n",
    "fold_id = 'F1'\n",
    "dataset_config['GDIS'].update(dataset_config['GDIS']['folds'][fold_id])\n",
    "del dataset_config['GDIS']['folds']\n",
    "print(dataset_config)\n",
    "\n",
    "# To determine the paths let's create another config \n",
    "experiment_config = {}\n",
    "experiment_config['Arguments'] = {}\n",
    "experiment_config['Arguments']['print_format'] = 'pdf'\n",
    "experiment_config['Arguments']['images_spx_path'] = parent_path + 'notebook/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the demo data\n",
    "demo_data = f'{parent_path}/notebook/demo_data/data_{fold_id}.pt'\n",
    "demo_data = torch.load(demo_data)\n",
    "demo_x = demo_data['demo_x']\n",
    "demo_masks = demo_data['demo_masks']\n",
    "demo_labels = demo_data['demo_labels']\n",
    "\n",
    "# Show some examples for reference\n",
    "tsize = demo_labels.shape[1]\n",
    "t0 = demo_labels[0].reshape((tsize, -1)).sum(dim = -1).nonzero(as_tuple = True)[0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 14))\n",
    "axs[0].imshow(demo_x[0,t0,:,:]), axs[0].set_title('x_demo_0')\n",
    "axs[0].imshow(demo_labels[0,t0,:,:]), axs[0].set_title('y_demo')\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SHIFT4L\n",
      "MY_MODEL(\n",
      "  (model): SHIFT4L(\n",
      "    (encoder_conv_1): Conv3d(5, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (encoder_conv_2): Conv3d(16, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (encoder_conv_3): Conv3d(32, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (encoder_conv_4): Conv3d(64, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (encoder_bn_1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (encoder_bn_2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (encoder_bn_3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (encoder_bn_4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (decoder_conv_4): Conv3d(128, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (decoder_conv_3): Conv3d(64, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (decoder_conv_2): Conv3d(32, 16, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (decoder_conv_1): Conv3d(16, 5, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (decoder_bn_4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (decoder_bn_3): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (decoder_bn_2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (decoder_bn_1): BatchNorm3d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (out_conv): Conv3d(5, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "    (activation): LeakyReLU(negative_slope=0.1)\n",
      "    (dropout): Dropout3d(p=0.1, inplace=False)\n",
      "    (_2d_pool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (_2d_upsample): Upsample(scale_factor=(1.0, 2.0, 2.0), mode=trilinear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = MY_MODEL(experiment_config, dataset_config, model_config)\n",
    "print(model)\n",
    "\n",
    "# Load the pretrained models\n",
    "pretrained_model_path = f'{parent_path}/notebook/pretrained_Models/{fold_id}'\n",
    "model_NL = model.load_state_dict(torch.load(pretrained_model_path + '_NL.pth'))\n",
    "model_SPLSC = model.load_state_dict(torch.load(pretrained_model_path + '_SPLSC.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluate\n",
    "model_NL.eval()\n",
    "model_SPLSC.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    # >>> Save outputs and predicctions for evaluation against indices\n",
    "    results_maps = {'y_hat_NL':[], 'y_hat_SPLSC':[], 'labels': [], 'masks':[]}\n",
    "        \n",
    "    # To correct for missing positions in the output\n",
    "    size_in = list(eval(dataset_config['GDIS']['input_size']))\n",
    "    size_out = list(eval(dataset_config['GDIS']['output_size']))\n",
    "    lost_border = int((size_in[0] - size_out[0])/2) \n",
    "    idt = dataset_config['GDIS']['idt']\n",
    "    \n",
    "    # Visualization variables for georeferenced plots\n",
    "    # img_extent = [minlon, maxlon, minlat, maxlat] coordinates where the data is defined\n",
    "    vismargin = dataset_config['GDIS']['vismargin']\n",
    "    resolution_adjust = int((size_in[0] - size_out[0])/2) * dataset_config['GDIS']['resolution']    \n",
    "    resolution_adjustvismargin = vismargin * dataset_config['GDIS']['resolution']\n",
    "    im_extent = (eval(dataset_config['GDIS']['lon_slice'])[0] + resolution_adjust, \n",
    "                 eval(dataset_config['GDIS']['lon_slice'])[1] - resolution_adjustvismargin,\n",
    "                 eval(dataset_config['GDIS']['lat_slice'])[1] + resolution_adjustvismargin,\n",
    "                 eval(dataset_config['GDIS']['lat_slice'])[0] - resolution_adjust)   \n",
    "    \n",
    "    # Central latitude and longitude\n",
    "    central_longitude = (im_extent[1] - abs(im_extent[0]))/2\n",
    "    central_latitude = (im_extent[3] - abs(im_extent[2]))/2\n",
    "    projection = ccrs.LambertConformal(central_longitude = central_longitude, \n",
    "                                       central_latitude = central_latitude)\n",
    "\n",
    "    # Loop over the demo dataset\n",
    "    for i in np.arange(tsize):\n",
    "        \n",
    "        # Get samples\n",
    "        x = demo_x[i]\n",
    "        masks = demo_masks[i]\n",
    "        labels = demo_labels[i]\n",
    "\n",
    "        # Evaluate \n",
    "        res_NL = model_NL.evaluate_map(x, masks, labels, mode = 'test')\n",
    "        res_SPLSC = model_SPLSC.evaluate_map(x, masks, labels, mode = 'test')\n",
    "\n",
    "        # Adapt masks to the output size\n",
    "        masks = masks[:,:,:,lost_border:,lost_border:]\n",
    "        masks = crop_variable(dataset_config['GDIS'], masks, temporal_crop = True)\n",
    "\n",
    "        # Converto to numpy, select time frame and remove extra dimensions (batch and variable)\n",
    "        # we take the first temporal instance\n",
    "        y_hat_NL = res_NL['output'][0,0,idt].cpu().numpy()\n",
    "        y_hat_SPLSC = res_SPLSC['output'][0,0,idt].cpu().numpy()\n",
    "        labels = res_NL['labels'][0,0,idt].cpu().numpy()\n",
    "        masks = masks[0,0,idt].cpu().numpy()\n",
    "\n",
    "        # For the missing positions \n",
    "        y_hat_NL[masks == 0] = np.nan\n",
    "        y_hat_SPLSC[masks == 0] = np.nan\n",
    "\n",
    "        # Save output\n",
    "        results_maps['y_hat_NL'].append(np.copy(y_hat_NL))\n",
    "        results_maps['y_hat_SPLSC'].append(np.copy(y_hat_SPLSC))\n",
    "        results_maps['labels'].append(np.copy(labels))\n",
    "        results_maps['masks'].append(np.copy(masks))\n",
    "        \n",
    "# Normalize the maps according to the max prob of each model (for comparing between them)            \n",
    "NL_min = np.nanmin(results_maps['y_hat_NL'])\n",
    "NL_max = np.nanmax(results_maps['y_hat_NL'])\n",
    "SPLSC_min = np.nanmin(results_maps['y_hat_SPLSC'])\n",
    "SPLSC_max = np.nanmax(results_maps['y_hat_SPLSC'])\n",
    "\n",
    "plot_maps_NL = (results_maps['y_hat_NL'] - NL_min) / (NL_max - NL_min)\n",
    "plot_maps_SPLSC = (results_maps['y_hat_SPLSC'] - SPLSC_min) / (SPLSC_max - SPLSC_min)\n",
    "\n",
    "#Plot label map\n",
    "for i in np.arange(tsize):\n",
    "    \n",
    "    # Plot    \n",
    "    fig = plt.figure(figsize = (10, 14)) \n",
    "    ax1 = plt.subplot(2, 1, 1, projection = projection)\n",
    "    ax2 = plt.subplot(2, 1, 2, projection = projection)  \n",
    "    im1 = geoplot2d(ax1, plot_maps_NL[i], im_extent, im_contour = results_maps['labels'][i])\n",
    "    im2 = geoplot2d(ax2, plot_maps_SPLSC[i], im_extent, im_contour = results_maps['labels'][i])\n",
    "    fig.colorbar(im1, ax = ax1, orientation = 'vertical')\n",
    "    fig.colorbar(im2, ax = ax2, orientation = 'vertical')\n",
    "    ax1.title.set_text('NL')\n",
    "    ax2.title.set_text('SPLSC')\n",
    "    plt.savefig(f\"{experiment_config['Arguments']['images_spx_path']}/t_{i}.{experiment_config['Arguments']['print_format']}\", \n",
    "                format = experiment_config['Arguments']['print_format'], bbox_inches = 'tight', pad_inches = 0)\n",
    "    plt.show()\n",
    "    plt.close(fig = fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought_am",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
